{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are fetching: https://www.zhihu.com/api/v4/columns/crossin/articles\n",
      "We are fetching: http://www.zhihu.com/api/v4/columns/crossin/articles?limit=10&offset=10\n",
      "We are fetching: http://www.zhihu.com/api/v4/columns/crossin/articles?limit=10&offset=20\n",
      "We are fetching: http://www.zhihu.com/api/v4/columns/crossin/articles?limit=10&offset=30\n",
      "We are fetching: http://www.zhihu.com/api/v4/columns/crossin/articles?limit=10&offset=40\n",
      "We are fetching: http://www.zhihu.com/api/v4/columns/crossin/articles?limit=10&offset=50\n",
      "We are fetching: http://www.zhihu.com/api/v4/columns/crossin/articles?limit=10&offset=60\n",
      "We are fetching: http://www.zhihu.com/api/v4/columns/crossin/articles?limit=10&offset=70\n",
      "We are fetching: http://www.zhihu.com/api/v4/columns/crossin/articles?limit=10&offset=80\n",
      "we are getting details of article:编程初学者如何使用搜索引擎\n",
      "we are getting details of article:如何直观地理解程序的运行过程？\n",
      "we are getting details of article:如何安装_Python_的第三方模块\n",
      "we are getting details of article:如何在一台电脑上同时使用_Python_2_和_Python_3\n",
      "we are getting details of article:Python_抓取网页乱码原因分析\n",
      "we are getting details of article:如何在_Python_中使用断点调试\n",
      "we are getting details of article:极简_Github_上手教程\n",
      "we are getting details of article:用_Python_实现你的量化交易策略\n",
      "we are getting details of article:想用_Python_做数据分析？先玩玩这个再说\n",
      "we are getting details of article:用_GitHub_+_Hexo_建立你的第一个博客\n",
      "we are getting details of article:Python_与_Excel_不得不说的事\n",
      "we are getting details of article:爆款游戏《贪吃蛇大作战》的_Python_实现\n",
      "we are getting details of article:Hexo(2)-部署博客及更新博文\n",
      "we are getting details of article:NBA_举办编程马拉松_-_数据分析时代的到来\n",
      "we are getting details of article:用Python分析公开数据选出高送转预期股票\n",
      "we are getting details of article:Python-Excel_模块哪家强？\n",
      "we are getting details of article:简单三步，用_Python_发邮件\n",
      "we are getting details of article:我在想，究竟是什么让编程“隔行如隔山”\n",
      "we are getting details of article:Python3.6新特性官方文档中文版\n",
      "we are getting details of article:今天，你抢到票了吗？\n",
      "we are getting details of article:把你开发的网站免费发布到互联网上\n",
      "we are getting details of article:个人开发者如何申请微信小程序\n",
      "we are getting details of article:史上首个_Python_x_微信小程序\n",
      "we are getting details of article:在这个什么都看脸的时代，如何用_GUI_提高_python_程序的颜值？\n",
      "we are getting details of article:ECharts+Python_给你的数据做“美颜”\n",
      "we are getting details of article:一行代码扫出“敬业福”\n",
      "we are getting details of article:数据分析：当赵雷唱民谣时他唱些什么？\n",
      "we are getting details of article:我去扒了杜蕾斯的微博\n",
      "we are getting details of article:还你系统空间的_Python_小程序\n",
      "we are getting details of article:如何用100行Python代码做出魔性声控游戏“八分音符酱”\n",
      "we are getting details of article:只学2个月编程能写出什么代码？\n",
      "we are getting details of article:给伸手党的福利：Python_新手入门引导\n",
      "we are getting details of article:世界上最伟大的巫师「咪蒙」\n",
      "we are getting details of article:喏，你们要的_PyCharm_快速上手指南\n",
      "we are getting details of article:微信机器人进化指南\n",
      "we are getting details of article:他们用实际行动告诉你，如何跨入编程的大门\n",
      "we are getting details of article:如何不被黑客“勒索”\n",
      "we are getting details of article:pycharm_如何程序运行后，仍可查看变量值？\n",
      "we are getting details of article:[转]_Instagram_在_PyCon_2017_的演讲摘要\n",
      "we are getting details of article:一点微小的程序\n",
      "we are getting details of article:编程新手：看懂很多示例，却依然写不好一个程序\n",
      "we are getting details of article:听说你好不容易写了个爬虫，结果没抓几个就被封了？\n",
      "we are getting details of article:Python有嘻哈：Crossin教你用代码写出押韵的verse\n",
      "we are getting details of article:Python情感分析：鹿晗的粉丝们究竟原谅他了吗？\n",
      "we are getting details of article:一名python学习者打开双11的正确姿势\n",
      "we are getting details of article:数百种编程语言，而我为什么要学_Python？\n",
      "we are getting details of article:关于“Python进高考”，我有句呵呵不知当讲不当讲\n",
      "we are getting details of article:折腾了几个月，终于调教出一架可以抢车位的无人机。然而…\n",
      "we are getting details of article:平安夜，Python_送你一顶圣诞帽_@微信官方\n",
      "we are getting details of article:直播答题？Python助你自动搜题之新手篇！\n",
      "we are getting details of article:[新手向视频]新版PyCharm创建项目为什么会有问题\n",
      "we are getting details of article:我在Python的艳阳里，大雪纷飞\n",
      "we are getting details of article:谈谈抢火车票的技术、技巧，以及暗藏其中的套路\n",
      "we are getting details of article:熬夜写了一个小游戏，向SpaceX聊表敬意\n",
      "we are getting details of article:你们这些死技术宅，还能不能一起愉快地玩耍了！\n",
      "we are getting details of article:我用_Python_算了下：编程教室的用户数哪天能到100万\n",
      "we are getting details of article:在知乎上学_Python_-_入门篇\n",
      "we are getting details of article:【招聘数据分析】Python就业前景如何\n",
      "we are getting details of article:你永远不知道猪队友会在什么时候坑了你\n",
      "we are getting details of article:3分钟破译朋友圈测试小游戏\n",
      "we are getting details of article:我们用程序整理出了一份Python英语高频词汇表，拿走不谢！\n",
      "we are getting details of article:10分钟了解区块链编程\n",
      "we are getting details of article:Python_向人工智能方向发展的技能树\n",
      "we are getting details of article:喜大普奔！Django官方文档终于出中文版了\n",
      "we are getting details of article:学了_Python_能用来做什么？\n",
      "we are getting details of article:​Python_3_新特性：类型注解\n",
      "we are getting details of article:你“听”过这些经典排序算法吗？\n",
      "we are getting details of article:Python单例模式(Singleton)的N种实现\n",
      "we are getting details of article:全菊变量和菊部变量\n",
      "we are getting details of article:我用Python做过些什么？\n",
      "we are getting details of article:[数据可视化]哪年高考最难？哪里高考最难？\n",
      "we are getting details of article:根据四万场比赛结果，我给今年世界杯每场比赛计算了胜率，冠军竟然是…\n",
      "we are getting details of article:关于函数参数传递，80%人都错了\n",
      "we are getting details of article:这个男人让你的爬虫开发效率提升8倍\n",
      "we are getting details of article:工欲善其事必先利其器：用什么写Python？\n",
      "we are getting details of article:像对象一样对待数据\n",
      "fail to get html for the reason: 'NoneType' object has no attribute 'prettify'\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'content' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2c86fc3531e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mget_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mget_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-2c86fc3531e9>\u001b[0m in \u001b[0;36mget_details\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0maid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mget_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'we are getting details of article:{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-2c86fc3531e9>\u001b[0m in \u001b[0;36mget_html\u001b[1;34m(aid, title, i)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fail to get html for the reason:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'<!DOCTYPE html><html><head><meta charset=\"utf-8\"></head><body><h1>{}</h1>{}</body></html>'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'zhihu/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'content' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#encoding=utf8\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "\n",
    "def get_list(url):\n",
    "    article_dict={}\n",
    "    while True:\n",
    "        print(\"We are fetching:\",url)\n",
    "        try:\n",
    "            r = requests.get(url,headers = headers)\n",
    "            content = r.json()\n",
    "        except Exception as e:\n",
    "            print('fail to get list for the reason:',e)\n",
    "            \n",
    "        for i in content['data']:\n",
    "            aid = i['id']\n",
    "            title = i['title']\n",
    "            article_dict[aid]=title\n",
    "            \n",
    "        if content['paging']['is_end']:\n",
    "            break\n",
    "            \n",
    "        url = content['paging']['next']\n",
    "        time.sleep(2)\n",
    "        \n",
    "    with open('zhihu/zhihu_ids.txt','w',encoding='utf-8') as f:\n",
    "        items = sorted(article_dict.items())\n",
    "        for k,y in items:\n",
    "            f.write('{} {}\\n'.format(k,y))\n",
    "            \n",
    "            \n",
    "def get_html(aid,title,i):\n",
    "    file_name = '{:0>3d}. {}.html'.format(i,title)\n",
    "    url = 'https://zhuanlan.zhihu.com/p/{}'.format(aid)\n",
    "    try:\n",
    "        html = requests.get(url,headers=headers).text\n",
    "        soup = BeautifulSoup(html,'lxml')\n",
    "    except Exception as e:\n",
    "        print('fail to get html for the reason:',e) \n",
    "        content = soup.find(class_='Post-RichText').prettify()\n",
    "        content = content.replace('data-actual','')\n",
    "        content = content.replace('h1>','h2>')\n",
    "        content = re.sub(r'<noscript>.*?</noscript>', '', content)\n",
    "    \n",
    "        \n",
    "    content = '<!DOCTYPE html><html><head><meta charset=\"utf-8\"></head><body><h1>{}</h1>{}</body></html>'.format(title,content)\n",
    "    with open('zhihu/'+file_name,'w',encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    time.sleep(2)\n",
    "\n",
    "    \n",
    "def get_details():\n",
    "    with open('zhihu/zhihu_ids.txt','r',encoding='utf-8') as f:\n",
    "        i = 1\n",
    "        for line in f:\n",
    "            lst = line.strip().split(' ')\n",
    "            aid = lst[0]\n",
    "            title = '_'.join(lst[1:])\n",
    "            get_html(aid,title,i)\n",
    "            print('we are getting details of article:{}'.format(title))\n",
    "            i += 1\n",
    "\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebkit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    url = 'https://www.zhihu.com/api/v4/columns/crossin/articles'\n",
    "\n",
    "    get_list(url)\n",
    "    get_details()\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
