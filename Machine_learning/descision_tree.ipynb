{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 3; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-629ab67bf285>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-629ab67bf285>\u001b[0m in \u001b[0;36mmake_tree\u001b[1;34m(count, root_data)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mleft_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright_set\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msplit_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtmp_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;31m#递归的划分新的子集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mentropy_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_recorder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleft_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[0mentropy_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_recorder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mselect_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-629ab67bf285>\u001b[0m in \u001b[0;36mmake_tree\u001b[1;34m(count, root_data)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0mselect_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'right'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mmin_entropy_recorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;31m# 计算左子集和右子集占总集合的比例\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mleft_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleft_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtmp_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dictionary update sequence element #0 has length 3; 2 is required"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 决策树实现异或XOR，相异为True，相同为False.\n",
    "# 数据格式[特征1，特征2，标签]\n",
    "data = np.array([[1, 1, False],[1, 0, True],[0,1, True],[0, 0, False]])\n",
    "label_index = 2 # 标签所在列\n",
    "\n",
    "\n",
    "features_num = 2 # 特征的数量\n",
    "features_possible_value = np.array([[0,1],[0,1]]) #各个特征可能的取值\n",
    "features_use_info = np.array([False,False]) # 各特征是否已被用来划分数据\n",
    "\n",
    "def split_set(dataset,feature_index, border_value):\n",
    "\n",
    "    # 按照指定特征的指定值划分数据集。\n",
    "    # 划分方法：左子集是指定特征小于等于指定值，右子集是指定特征大于指定值\n",
    "    left_set_index  = dataset[:,feature_index]<=border_value\n",
    "    right_set_index = dataset[:,feature_index]>border_value\n",
    "\n",
    "    return dataset[left_set_index], dataset[right_set_index]\n",
    "\n",
    "# 计算信息熵，p是当前这个类别占整个集合的比例\n",
    "def entropy(p):\n",
    "    if p==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -p * np.log2(p)\n",
    "\n",
    "#计算集合的熵\n",
    "def entropy_dataset(dataset):\n",
    "    if dataset.shape[0]==0:\n",
    "        return 0\n",
    "    # 先计算两种类别的数据的占比\n",
    "    p_true = (dataset[:,label_index]==True).shape[0]/dataset.shape[0]\n",
    "    p_false = 1.0 - p_true #（由于只有两个分类所以可以这么算）\n",
    "    return entropy(p_true) + entropy(p_false)\n",
    "\n",
    "\n",
    "def make_tree(count,root_data):\n",
    "    min_entropy_recorder = {}\n",
    "    #count: 序号，记录是第几次划分\n",
    "    min_entropy_recorder[count]={'entropy':np.inf}# 记录各种划分方法下的最小的熵和对应划分方法\n",
    "    tmp_data = root_data\n",
    "\n",
    "    # 如果数据已经都是一个类了那就不用再划分了\n",
    "    if np.alltrue(tmp_data[:,label_index]==True):\n",
    "        return 0,{} #已经都是一个类就熵是0，不用做任何划分动作\n",
    "    \n",
    "    #如果特征用完了,只用返回熵，不用做任何动作\n",
    "    if np.alltrue(features_use_info) or count>features_num:\n",
    "        return entropy_dataset(root_data),{}\n",
    "\n",
    "    # 1. 遍历剩下没有使用的特征\n",
    "    for tmp_feature in np.nditer(np.where(features_use_info==False)):\n",
    "        # 2. 遍历当前特征各种取值情况\n",
    "        tmp_values = features_possible_value[tmp_feature]\n",
    "        features_use_info[tmp_feature]=True\n",
    "        for v in np.nditer(tmp_values):\n",
    "\n",
    "            # 3. 按照当前特征的选定值将现在的集合划分为两个子集\n",
    "            result = split_set(tmp_data,tmp_feature,v)\n",
    "            print(len(result))\n",
    "            left_set,right_set  = split_set(tmp_data,tmp_feature,v)\n",
    "            #递归的划分新的子集\n",
    "            entropy_left, left_recorder = make_tree(count+1,left_set)\n",
    "            entropy_right, right_recorder = make_tree(count+1,right_set)\n",
    "            select_child = ''\n",
    "            # 哪个子集划分的熵最小就选哪个子集作为划分方案\n",
    "            if entropy_left<entropy_right:\n",
    "                select_child = 'left'\n",
    "                min_entropy_recorder.update(left_set)\n",
    "            else:\n",
    "                select_child = 'right'\n",
    "                min_entropy_recorder.update(right_set)\n",
    "            # 计算左子集和右子集占总集合的比例\n",
    "            left_rate = left_set.shape[0]/tmp_data.shape[0]\n",
    "            right_rate = right_set.shape[0]/tmp_data.shape[0]\n",
    "            entropy_all = left_rate*entropy_left + right_rate*entropy_left\n",
    "            \n",
    "            # 如果当前划分方法是目前最好，那就记录当前的划分方法和熵\n",
    "            if min_entropy_recorder[count]['entropy']  > entropy_all:\n",
    "                min_entropy_recorder[count]['entropy'] = entropy_all\n",
    "                min_entropy_recorder[count]['feature'] = tmp_feature\n",
    "                min_entropy_recorder[count]['border']  = v\n",
    "                min_entropy_recorder[count]['select_child']  = select_child\n",
    "                pass\n",
    "            pass\n",
    "        features_use_info[tmp_feature]=False #回溯\n",
    "        pass #end循环\n",
    "    return min_entropy_recorder[count]['entropy'], min_entropy_recorder\n",
    "    pass # end函数\n",
    "\n",
    "\n",
    "print(make_tree(0,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
