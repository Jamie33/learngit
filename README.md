# 自我介绍 / About Me

## 徐玖 / Jamie

- **四川外国语大学 翻译硕士**  Holding a Master of Translation and Interpreting from Sichuan International Studies University

- **英语翻译4年从业经验** Having five years of work experience in English translation

- **用 Python 消除重复性工作** Able to create Python scripts that help me in repetitive tasks

---


> [编译文章 / Previous translation work](https://www.leiphone.com/author/xusan )（雷锋网认证作者592篇 / 592 translated articles ）

> [个人博客 / Blog](https://jamie33.github.io/) (基于github pages 和 hexo 搭建 / Based on github pages and hexo)


> 爬虫脚本

- [淘宝台湾地址抓取](https://github.com/Jamie33/learngit/tree/master/Spider/TaobaoAddress#%E6%B7%98%E5%AE%9D%E5%8F%B0%E6%B9%BE%E5%9C%B0%E5%9D%80%E6%8A%93%E5%8F%96) / To get Taiwan addresses from Taobao
- [Google 搜索引擎相关邮箱爬取](https://github.com/Jamie33/learngit/tree/master/Spider/GoogleEmail#%E5%8A%A8%E6%80%81%E6%B8%B2%E6%9F%93-selenium%E8%A7%A3%E6%9E%90%E5%BA%93-pyquery%E6%95%B0%E6%8D%AE%E5%BA%93-mongodb) / To collect emails from google search engine
- [速卖通 aliexpress 牛仔裤品类爬虫](https://github.com/Jamie33/learngit/tree/master/Spider/Aliexpress#%E5%8A%A8%E6%80%81%E6%B8%B2%E6%9F%93-selenium%E8%A7%A3%E6%9E%90%E5%BA%93-pyquery%E6%95%B0%E6%8D%AE%E5%BA%93-mongodb) / To acquire items' information of jeans from aliexpress
- [amazon 牛仔裤品类爬虫](https://github.com/Jamie33/learngit/tree/master/Spider/AmazonJeans#amazon%E7%89%9B%E4%BB%94%E8%A3%A4%E5%93%81%E7%B1%BB%E7%88%AC%E8%99%AB) / To obtain data of jeans category from amazon
- [AppAnnie App Top100 排行榜以及其关键词](https://github.com/Jamie33/learngit/tree/master/Spider/AppAnnie#appannie-app-top100%E4%BB%A5%E5%8F%8A%E5%85%B6%E5%85%B3%E9%94%AE%E8%AF%8D) / To get App rank and its keywords in AppAnnie
- [Shopee 、Lazada 、Myntra 三大平台爬虫](https://github.com/Jamie33/learngit/tree/master/Spider/ShopCrawl#shopeelazadamyntra-%E4%B8%89%E5%A4%A7%E5%B9%B3%E5%8F%B0%E7%88%AC%E8%99%AB) / Three spiders on Shopee, Lazada and Myntra
- [shopee 印尼站高价位爆款数据抓取](https://github.com/Jamie33/learngit/tree/master/Spider/ShopeeSales#shopee%E5%8D%B0%E5%B0%BC%E7%AB%99%E9%AB%98%E4%BB%B7%E4%BD%8D%E7%88%86%E6%AC%BE%E6%95%B0%E6%8D%AE%E6%8A%93%E5%8F%96) / To crawl hot sale with high prices in shopee Indonesia
- [shopee 台湾站爆款抓取](https://github.com/Jamie33/learngit/tree/master/Spider/ShopeeSales#shopee-%E5%8F%B0%E6%B9%BE%E7%AB%99%E7%88%86%E6%AC%BE%E6%8A%93%E5%8F%96)/ To get hot-sale items in shopee Taiwan


>利用框架 scrapy 爬取数据 / To crawl data using scrapy framework 

- [利用 scrapy 爬取 Lavada 越南站美妆个护产品](https://github.com/Jamie33/learngit/tree/master/ScrapyProject/lazadaVN#lazada%E7%BE%8E%E5%A6%86%E4%B8%AA%E6%8A%A4%E4%BA%A7%E5%93%81%E7%88%AC%E5%8F%96%E9%9C%80%E6%B1%82)/ To crawl product data from Lazada Vietnam using scrapy
- [获取 Lazada 越南站美妆类数据，并上传至后台](https://github.com/Jamie33/learngit/tree/master/ScrapyProject/shopeeTW#lazada-%E8%B6%8A%E5%8D%97%E7%AB%99%E7%BE%8E%E5%A6%86%E7%B1%BB%E6%95%B0%E6%8D%AE) / Collecting cosmetics data from Lazada Vietnam  and uploading them to the back-end platform
- [抓取 Tiki越南站美妆类数据](https://github.com/Jamie33/learngit/tree/master/ScrapyProject/tiki#tiki%E8%B6%8A%E5%8D%97%E7%AB%99%E7%BE%8E%E5%A6%86%E7%B1%BB%E6%95%B0%E6%8D%AE) / Acquiring cosmetics data from Tiki Vietnam
- [爬取 Sendo 越南站美妆类数据](https://github.com/Jamie33/learngit/tree/master/ScrapyProject/tiki#sendo%E8%B6%8A%E5%8D%97%E7%AB%99%E7%BE%8E%E5%A6%86%E7%B1%BB%E6%95%B0%E6%8D%AE) / Crawling cosmetics data from Sendo Vietnam
- [1688商品爬取并上传至后台](https://github.com/Jamie33/learngit/tree/master/newScrapy/login1688#1688%E5%95%86%E5%93%81%E7%88%AC%E5%8F%96%E5%95%86%E5%93%81%E4%B8%8A%E4%BC%A0%E5%90%8E%E5%8F%B0) / Getting information of items from 1688 and uploading them to the back-end platform


>利用 python 进行数据分析和可视化处理 / Data analysis and visualization using python

- [利用 python 对 shopee TW站 八大品类商品进行数据分析](https://jamie33.github.io/PageDemo/shopee_data_analysis_TW.html)/ Data analysis on eight merchandise categories from shopee Taiwan using python
- [利用 python 对 shopee 印尼站 四大品类商品进行数据分析](https://jamie33.github.io/PageDemo/shopee_data_analysis.html )/ Data analysis on four merchandise categories from shopee Indonesia using python


> 利用 appium 控制手机的脚本 / Making small amount of money from automating the cellphone using appium

- [Python3 + Appium + Andriod 趣头条脚本，轻松薅羊毛](https://zhuanlan.zhihu.com/p/67518154) / Making small amount of money from automating Qutoutiao app
- [Python3 + Appium + Andriod 东方头条脚本，轻松薅羊毛](https://zhuanlan.zhihu.com/p/68038338) / Making small amount of money from automating EastNews app


> python 对接 API / Python with API

- [利用百度识别接口和百度翻译接口识别并翻译图片](https://github.com/Jamie33/learngit/tree/master/Ocr#%E5%9B%BE%E7%89%87%E8%AF%86%E5%88%AB%E7%BF%BB%E8%AF%91%E5%8A%9F%E8%83%BD%E8%84%9A%E6%9C%AC%E5%BC%80%E5%8F%91)/ Recognize and translate the pictures using Baidu Recognition and translation API)


> 满足日常生活需求写的小脚本 / Python scripts for daily needs

- [深圳图书馆自动预借脚本](https://zhuanlan.zhihu.com/p/47664186)/ Borrowing books whenever they are available from online library system
- [论坛每天自动获取积分的脚本](https://zhuanlan.zhihu.com/p/41280394 )/ Getting points from the forum on a daily basis

- [微信币价查询机器人](https://zhuanlan.zhihu.com/p/41055423) / A Wechat bot for checking prices of cryptocurrenies

---

如果你想认识我，用微信扫描下方二维码!

In case you want to get to know me, scan the QR code below to add me on Wechat!

![微信图片_20181122103825_副本.jpg](https://i.loli.net/2018/11/26/5bfb556d1ed9b.jpg)
